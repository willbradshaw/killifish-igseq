##############################################################################
## SNAKEFILE
## PIPELINE: Immunoglobulin sequencing analysis
## SUB-PIPELINE: Downstream analysis
## FILE: igor
## AUTHOR: Will Bradshaw
##############################################################################
## Perform generative modelling with IGoR
##############################################################################

#-----------------------------------------------------------------------------
# Specify input and output directories
#-----------------------------------------------------------------------------

out_dir_igor = os.path.join(out_dir_analysis, "igor")
log_dir_igor = os.path.join(log_dir_analysis, "igor")
# TODO: Add sample specificity here?

igor_path = os.path.join(os.path.dirname(config["base_path_analysis"]),\
    "../envs/software/igor/bin/igor")
igor_model_default = os.path.join(os.path.dirname(igor_path),\
    "../share/igor/models/human/bcr_heavy/models/model_parms.txt")
igor_script_dir = os.path.join(os.path.dirname(config["base_path_analysis"]),\
    "../scripts")

#-----------------------------------------------------------------------------
# Configure input files (other than Ig sequences)
#-----------------------------------------------------------------------------

rule igor_extract_j_anchor:
    """Generate IGoR J-anchor file from input auxiliary file."""
    input: config["j_aux_file"]
    output: os.path.join(out_dir_igor, "anchors/J.csv")
    log: os.path.join(log_dir_igor, "extract_j_anchor.dbg")
    conda: env_r_analysis
    threads: config["threads"]["min"]
    params:
        aux = aux_dir_analysis,
    script: os.path.join(script_dir_analysis, "extract_j_anchors.R")

rule igor_extract_v_anchor:
    """Generate IGoR V-anchor file from IMGT-gapped V-sequences."""
    input: config["segment_paths"]["V_IMGT"]
    output: os.path.join(out_dir_igor, "anchors/V.csv")
    log: os.path.join(log_dir_igor, "extract_v_anchor.dbg")
    conda: env_r_analysis
    threads: config["threads"]["min"]
    params:
        aux = aux_dir_analysis,
    script: os.path.join(script_dir_analysis, "extract_v_anchors.R")

rule igor_configure_model:
    """Prepare default model parameter file for use by IGoR."""
    output: os.path.join(out_dir_igor, "default_model.txt")
    log: os.path.join(log_dir_igor, "configure_model.dbg")
    params:
        input = config["igor_default_model"],
        default = igor_model_default,
    shell:
        "if [[ -z '{params.input}' ]]; then "
        "cp {params.default} {output} &> {log}; else "
        "cp {params.input} {output} &> {log}; fi"

rule igor_igblast_make_db:
    """Make BLAST databases for IgBLAST alignment"""
    input: lambda wildcards: config["segment_paths"][wildcards.segment.upper()]
    output: os.path.join(out_dir_igor, "igblast/{segment}.nin")
    log: os.path.join(log_dir_igor, "igblast/make_blast_db_{segment}.dbg")
    conda: env_main_analysis
    params:
        prefix = lambda wildcards, output: \
            os.path.abspath(os.path.splitext(output[0])[0])
    shell:
        "makeblastdb -parse_seqids -dbtype nucl -in {input} "
        "-out {params.prefix} &> {log}"

#-----------------------------------------------------------------------------
# Obtain nonfunctional semi-naive sequences for IGoR
#-----------------------------------------------------------------------------

rule igor_configure_db:
    """Prepare Change-O DB for sequence extraction."""
    input: os.path.join(out_dir_shm,"seqs-all_clones-collapsed-model.tab")
    output: os.path.join(out_dir_igor, "sequences/seqs-all_igor-ready.tab")
    log: os.path.join(log_dir_igor, "sequences/seqs-all_configure-db.dbg")
    conda: env_r_analysis
    threads: config["threads"]["min"]
    params:
        aux = aux_dir_analysis,
        individuals = config["igor_individuals"],
        group_field = config["igor_group_by"],
        groups = config["igor_groups"],
        collapsed = True,
    script: os.path.join(script_dir_analysis, "configure_igor_db.R")

rule igor_extract_sequences_initial:
    """Extract clonal consensus sequences for functional checking."""
    input: os.path.join(out_dir_igor, "sequences/seqs-all_igor-ready.tab")
    output: os.path.join(out_dir_igor, "sequences/seqs-all_igor-ready.fasta")
    log: os.path.join(log_dir_igor, "sequences/extract-sequences-initial.dbg")
    conda: env_main_analysis
    params:
        prefix = lambda wildcards, output: \
            os.path.abspath("_".join(output[0].split("_")[:-1])),
        id_field = "SEQUENCE_ID",
        seq_field = "SEQUENCE_OUT",
        meta_fields = ["INDIVIDUAL", "REPLICATE", config["igor_group_by"]],
    shell:
        "ConvertDb.py fasta -d {input} -o {output} --if {params.id_field} "
        "--sf {params.seq_field} --mf {params.meta_fields} &> {log}"

rule igor_igblast_align:
    """Align consensus sequences to VDJ databases with IgBLAST"""
    input:
        seq = os.path.join(out_dir_igor,"sequences/seqs-all_igor-ready.fasta"),
        v = os.path.join(out_dir_igor, "igblast/v.nin"),
        d = os.path.join(out_dir_igor, "igblast/d.nin"),
        j = os.path.join(out_dir_igor, "igblast/j.nin"),
        aux = config["j_aux_file"]
    output: os.path.join(out_dir_igor, "igblast/align.fmt7")
    log: os.path.join(log_dir_igor, "sequences/igor_igblast_align.dbg")
    conda: env_main_analysis
    params:
        v = lambda wildcards, input: os.path.splitext(input.v)[0],
        d = lambda wildcards, input: os.path.splitext(input.d)[0],
        j = lambda wildcards, input: os.path.splitext(input.j)[0],
    threads: min(8, config["threads"]["med"]) # IgBLAST can't handle >8
    shell:
        "export IGDATA=${{CONDA_PREFIX}}/share/igblast; echo $IGDATA &> {log};"
        "igblastn -ig_seqtype Ig -domain_system imgt -num_threads {threads} "
        "-query {input.seq} -out {output} -germline_db_V {params.v} "
        "-germline_db_J {params.j} -germline_db_D {params.d} "
        "-auxiliary_data {input.aux} -outfmt '7 std qseq sseq btop' "
        " &>> {log}"

rule igor_changeo_make_db:
    """Make sequence database from IgBLAST output with Change-O"""
    input:
        seq = os.path.join(out_dir_igor,"sequences/seqs-all_igor-ready.fasta"),
        igblast = os.path.join(out_dir_igor, "igblast/align.fmt7"),
        v = config["segment_paths"]["V"],
        d = config["segment_paths"]["D"],
        j = config["segment_paths"]["J"],
    output: os.path.join(out_dir_igor, "sequences/seqs-all_db-pass.tab")
    conda: env_main_analysis
    log: os.path.join(log_dir_igor, "sequences/igor_make_changeo_db.dbg")
    params:
        prefix = lambda wildcards, output: \
            os.path.abspath("_".join(output[0].split("_")[:-1])),
    shell:
        "MakeDb.py igblast --regions --scores --partial --asis-calls "
        " --cdr3 -i {input.igblast} -s {input.seq} --outname {params.prefix} "
        "-r {input.v} {input.d} {input.j} &> {log};"

rule igor_changeo_split_functional:
    """Identify and separate functional from nonfunctional sequences"""
    input: os.path.join(out_dir_igor, "sequences/seqs-all_db-pass.tab")
    output:
        p = os.path.join(out_dir_igor, "sequences/seqs-all_FUNCTIONAL-T.tab"),
        f = os.path.join(out_dir_igor, "sequences/seqs-all_FUNCTIONAL-F.tab"),
    conda: env_main_analysis
    log: os.path.join(log_dir_igor, "sequences/igor_split_functional.dbg")
    threads: config["threads"]["min"]
    params:
        prefix = lambda wildcards, output: \
            os.path.abspath("_".join(output[0].split("_")[:-1])),
    shell:
        "ParseDb.py split -f FUNCTIONAL --outname {params.prefix} "
        "-d {input} &> {log}; "
        "if [[ ! -e {output.p} ]]; then touch {output.p} &>> {log}; fi; "
        "if [[ ! -e {output.f} ]]; then touch {output.f} &>> {log}; fi"

#-----------------------------------------------------------------------------
# Prepare input Ig sequences from processed DB
#-----------------------------------------------------------------------------

rule igor_split_individual:
    """Split configured DB by individual."""
    input: os.path.join(out_dir_igor, "sequences/seqs-all_FUNCTIONAL-F.tab")
    output: expand(os.path.join(out_dir_igor,\
        "sequences/seqs-all_INDIVIDUAL-{i}.tab"),\
            i = config["igor_individuals"])
    log: os.path.join(out_dir_igor,\
        "sequences/split-db-individual.dbg")
    params:
        outdir = lambda wildcards, output: os.path.dirname(output[0]),
        outpref = "seqs-all"
    threads: config["threads"]["min"]
    conda: env_main_analysis
    shell:
        "ParseDb.py split -d {input} -f INDIVIDUAL --outdir {params.outdir} "
        "--outname {params.outpref} &> {log}"

rule igor_split_group:
    """Split configured DB by group."""
    input: os.path.join(out_dir_igor, "sequences/seqs-all_FUNCTIONAL-F.tab")
    output: expand(os.path.join(out_dir_igor,\
        "sequences/seqs-all_{group}-{value}.tab"),\
        group = config["igor_group_by"], value = config["igor_groups"])
    log: os.path.join(out_dir_igor, "sequences/split-db-group.dbg")
    params:
        outdir = lambda wildcards, output: os.path.dirname(output[0]),
        outpref = "seqs-all",
        group = config["igor_group_by"],
    threads: config["threads"]["min"]
    conda: env_main_analysis
    shell:
        "ParseDb.py split -d {input} -f {params.group} "
        "--outdir {params.outdir} --outname {params.outpref} &> {log}"

rule igor_extract_sequences:
    """Extract DB sequences into a FASTA file."""
    input: os.path.join(out_dir_igor,\
        "sequences/seqs-all_{field}-{value}.tab")
    output: os.path.join(out_dir_igor,\
        "sequences/seqs-all_{field}-{value}.fasta")
    log: os.path.join(log_dir_igor,\
        "sequences/seqs-all_{field}-{value}_extract-sequences.dbg")
    conda: env_main_analysis
    params:
        prefix = lambda wildcards, output: \
            os.path.abspath("_".join(output[0].split("_")[:-1])),
        id_field = "SEQUENCE_ID",
        seq_field = "SEQUENCE_INPUT"
    shell:
        "ConvertDb.py fasta -d {input} -o {output} --if {params.id_field} "
        "--sf {params.seq_field} &> {log}"

#-----------------------------------------------------------------------------
# Infer generative models with IGoR
#-----------------------------------------------------------------------------

out_dir_igor_run = os.path.join(out_dir_igor, "{field}-{value}")
log_dir_igor_run = os.path.join(log_dir_igor, "{field}-{value}")

rule igor_read_seqs:
    """Read in sequences for alignment with IGoR."""
    input: os.path.join(out_dir_igor,\
        "sequences/seqs-all_{field}-{value}.fasta")
    output: os.path.join(out_dir_igor_run, "aligns/indexed_sequences.csv")
    params:
        wd = lambda wildcards: os.path.join(out_dir_igor,\
            wildcards.field + "-" + wildcards.value),
        cmd = igor_path,
    log: os.path.join(log_dir_igor_run, "read_seqs.dbg")
    threads: config["threads"]["min"]
    shell:
        "{params.cmd} -set_wd {params.wd} -threads {threads} "
        "-read_seqs {input} &> {log}"

rule igor_align:
    """Align sequences to VDJ databases with IGoR."""
    input:
        seqs = os.path.join(out_dir_igor_run,"aligns/indexed_sequences.csv"),
        v = config["segment_paths"]["V"],
        d = config["segment_paths"]["D"],
        j = config["segment_paths"]["J"],
        vanchor = os.path.join(out_dir_igor, "anchors/V.csv"),
        janchor = os.path.join(out_dir_igor, "anchors/J.csv"),
    output:
        info = os.path.join(out_dir_igor_run, "aligns/aligns_info.out"),
        valn = os.path.join(out_dir_igor_run, "aligns/V_alignments.csv"),
        daln = os.path.join(out_dir_igor_run, "aligns/D_alignments.csv"),
        jaln = os.path.join(out_dir_igor_run, "aligns/J_alignments.csv"),
    params:
        wd = lambda wildcards: os.path.join(out_dir_igor,\
            wildcards.field + "-" + wildcards.value),
        cmd = igor_path,
    log: os.path.join(log_dir_igor_run, "align.dbg")
    threads: config["threads"]["med"]
    shell:
        "{params.cmd} -set_wd {params.wd} -threads {threads} "
        "-set_genomic --V {input.v} --D {input.d} --J {input.j} "
        "-set_CDR3_anchors --V {input.vanchor} --J {input.janchor} "
        "-align --all &> {log}"

rule igor_infer_model:
    """Infer generative model from VDJ alignments."""
    input:
        aligns = os.path.join(out_dir_igor_run, "aligns/aligns_info.out"),
        v = config["segment_paths"]["V"],
        d = config["segment_paths"]["D"],
        j = config["segment_paths"]["J"],
        vanchor = os.path.join(out_dir_igor, "anchors/V.csv"),
        janchor = os.path.join(out_dir_igor, "anchors/J.csv"),
        model = os.path.join(out_dir_igor, "default_model.txt"),
    output:
        os.path.join(out_dir_igor_run, "inference/inference_info.out")
    params:
        wd = lambda wildcards: os.path.join(out_dir_igor,\
            wildcards.field + "-" + wildcards.value),
        cmd = igor_path,
    log: os.path.join(log_dir_igor_run, "inference.dbg")
    threads: config["threads"]["max"]
    shell:
        "{params.cmd} -set_wd {params.wd} -threads {threads} "
        "-set_custom_model {input.model} "
        "-set_genomic --V {input.v} --D {input.d} --J {input.j} "
        "-set_CDR3_anchors --V {input.vanchor} --J {input.janchor} "
        "-infer &> {log}" # TODO: Add more parameters?

rule igor_evaluate_model:
    """Evaluate inferred model and generate output."""
    input:
        infers = os.path.join(out_dir_igor_run,"inference/inference_info.out"),
        aligns = os.path.join(out_dir_igor_run, "aligns/aligns_info.out"),
        model = os.path.join(out_dir_igor, "default_model.txt"),
    output: # TODO: Add more here as needed for downstream rules
        evals = os.path.join(out_dir_igor_run, "evaluate/inference_info.out"),
        scenarios = os.path.join(out_dir_igor_run,\
            "output/best_scenarios_counts.csv"),
        pgen = os.path.join(out_dir_igor_run, "output/Pgen_counts.csv"),
        marginals = os.path.join(out_dir_igor_run,\
            "evaluate/final_marginals.txt"),
        parms = os.path.join(out_dir_igor_run,\
            "evaluate/final_parms.txt"),
    params:
        wd = lambda wildcards: os.path.join(out_dir_igor,\
            wildcards.field + "-" + wildcards.value),
        cmd = igor_path,
    log: os.path.join(log_dir_igor_run, "evaluate.dbg")
    threads: config["threads"]["med"]
    shell:
        "{params.cmd} -set_wd {params.wd} -threads {threads} "
        "-load_last_inferred -evaluate "
        "-output --scenarios 5 --Pgen --coverage VJ_gene &> {log}"
        # TODO: Add D coverage inference once this works

#-----------------------------------------------------------------------------
# Extract model information from output files
#-----------------------------------------------------------------------------

rule extract_segment_dists:
    """Extract V/D/J selection distributions from IGoR output."""
    input:
        marginals = os.path.join(out_dir_igor_run, \
            "evaluate/final_marginals.txt"),
        parms = os.path.join(out_dir_igor_run,\
            "evaluate/final_parms.txt"),
    output:
        v = os.path.join(out_dir_igor_run, "output/segments/V.tsv"),
        d = os.path.join(out_dir_igor_run, "output/segments/D.tsv"),
        j = os.path.join(out_dir_igor_run, "output/segments/J.tsv"),
        vj = os.path.join(out_dir_igor_run, "output/segments/VJ.tsv"),
        vdj = os.path.join(out_dir_igor_run, "output/segments/VDJ.tsv"),
    conda: env_pygor_analysis
    log: os.path.join(log_dir_igor_run, "extract-segment-dists.dbg")
    params:
        script = os.path.join(igor_script_dir,\
            "igor_extract_segment_dists.py"),
        indir = lambda wildcards, input: os.path.dirname(input.parms),
        outdir = lambda wildcards, output: os.path.dirname(output.v),
        id = lambda wildcards: wildcards.value,
    threads: config["threads"]["min"]
    shell:
        "export PYTHONNOUSERSITE=True;"
        "{params.script} {params.indir} {params.outdir} {params.id} &> {log}"

rule combine_segment_dists:
    """Combine segment distributions into a single table."""
    input:
        os.path.join(out_dir_igor_run, "output/segments/V.tsv"),
        os.path.join(out_dir_igor_run, "output/segments/D.tsv"),
        os.path.join(out_dir_igor_run, "output/segments/J.tsv"),
        os.path.join(out_dir_igor_run, "output/segments/VJ.tsv"),
        os.path.join(out_dir_igor_run, "output/segments/VDJ.tsv"),
    output: os.path.join(out_dir_igor_run, "output/segments.tsv")
    log: os.path.join(log_dir_igor_run, "combine-segment-dists.dbg")
    conda: env_r_analysis
    params:
        aux = aux_dir_analysis,
    script: os.path.join(script_dir_analysis, "merge_dbs.R")
    #script: os.path.join(script_dir_analysis, "igor_combine_segment_dists.R")

rule extract_insertion_dists:
    """Extract insertion distributions from IGoR output."""
    input:
        marginals = os.path.join(out_dir_igor_run,\
            "evaluate/final_marginals.txt"),
        parms = os.path.join(out_dir_igor_run,\
            "evaluate/final_parms.txt"),
    output:
        os.path.join(out_dir_igor_run, "output/inserts.tsv"),
    conda: env_pygor_analysis
    log: os.path.join(log_dir_igor_run, "extract-insertion-dists.dbg")
    params:
        script = os.path.join(igor_script_dir,\
            "igor_extract_insert_dists.py"),
        indir = lambda wildcards, input: os.path.dirname(input.parms),
        outdir = lambda wildcards, output: os.path.dirname(output[0]),
        id = lambda wildcards: wildcards.value,
    threads: config["threads"]["min"]
    shell:
        "export PYTHONNOUSERSITE=True;"
        "{params.script} {params.indir} {params.outdir} {params.id} &> {log}"

rule extract_deletion_dists:
    """Extract deletion distributions from IGoR output."""
    input:
        marginals = os.path.join(out_dir_igor_run,\
            "evaluate/final_marginals.txt"),
        parms = os.path.join(out_dir_igor_run,\
            "evaluate/final_parms.txt"),
    output:
        os.path.join(out_dir_igor_run, "output/deletes.tsv"),
    conda: env_pygor_analysis
    log: os.path.join(log_dir_igor_run, "extract-deletion-dists.dbg")
    params:
        script = os.path.join(igor_script_dir,\
            "igor_extract_delete_dists.py"),
        indir = lambda wildcards, input: os.path.dirname(input.parms),
        outdir = lambda wildcards, output: os.path.dirname(output[0]),
        id = lambda wildcards: wildcards.value,
    threads: config["threads"]["min"]
    shell:
        "export PYTHONNOUSERSITE=True;"
        "{params.script} {params.indir} {params.outdir} {params.id} &> {log}"

rule combine_indel_dists:
    """Combine indel distributions into a single table."""
    input:
        os.path.join(out_dir_igor_run, "output/inserts.tsv"),
        os.path.join(out_dir_igor_run, "output/deletes.tsv"),
    output: os.path.join(out_dir_igor_run, "output/indels.tsv")
    log: os.path.join(log_dir_igor_run, "combine-indel-dists.dbg")
    conda: env_r_analysis
    params:
        aux = aux_dir_analysis,
    script: os.path.join(script_dir_analysis, "merge_dbs.R")

rule extract_recombination_entropies:
    """Extract recombination entropies from IGoR output."""
    input:
        marginals = os.path.join(out_dir_igor_run,\
            "evaluate/final_marginals.txt"),
        parms = os.path.join(out_dir_igor_run,\
            "evaluate/final_parms.txt"),
    output:
        os.path.join(out_dir_igor_run, "output/entropies.tsv"),
    conda: env_pygor_analysis
    log: os.path.join(log_dir_igor_run, "extract-recombination-entropies.dbg")
    params:
        script = os.path.join(igor_script_dir,\
            "igor_extract_recombination_entropy.py"),
        indir = lambda wildcards, input: os.path.dirname(input.parms),
        outdir = lambda wildcards, output: os.path.dirname(output[0]),
        id = lambda wildcards: wildcards.value,
    threads: config["threads"]["min"]
    shell:
        "export PYTHONNOUSERSITE=True;"
        "{params.script} {params.indir} {params.outdir} {params.id} &> {log}"

#-----------------------------------------------------------------------------
# Merge extracted TSVs across all samples
#-----------------------------------------------------------------------------

rule merge_segment_dists:
    """Merge IGoR segment choice distributions across all groups."""
    input: lambda wildcards: expand(os.path.join(out_dir_igor_run,\
        "output/segments.tsv"),\
        field = wildcards.field, value = config["igor_individuals"] if \
            wildcards.field == "INDIVIDUAL" else config["igor_groups"])
    output: os.path.join(out_dir_igor,\
        "{field}-all/output/segments.tsv")
    log: os.path.join(log_dir_igor,\
        "merge_segment_dists_{field}.dbg")
    conda: env_r_analysis
    threads: config["threads"]["min"]
    params:
        aux = aux_dir_analysis,
    script: os.path.join(script_dir_analysis, "merge_dbs.R")

rule merge_indel_dists:
    """Merge IGoR indel distributions across all groups."""
    input: lambda wildcards: expand(os.path.join(out_dir_igor_run,\
        "output/indels.tsv"),\
        field = wildcards.field, value = config["igor_individuals"] if \
            wildcards.field == "INDIVIDUAL" else config["igor_groups"])
    output: os.path.join(out_dir_igor,\
        "{field}-all/output/indels.tsv")
    log: os.path.join(log_dir_igor,\
        "merge_indel_dists_{field}.dbg")
    conda: env_r_analysis
    threads: config["threads"]["min"]
    params:
        aux = aux_dir_analysis,
    script: os.path.join(script_dir_analysis, "merge_dbs.R")

rule merge_recombination_entropies:
    """Merge IGoR recombination_entropies across all groups."""
    input: lambda wildcards: expand(os.path.join(out_dir_igor_run,\
        "output/entropies.tsv"),\
        field = wildcards.field, value = config["igor_individuals"] if \
            wildcards.field == "INDIVIDUAL" else config["igor_groups"])
    output: os.path.join(out_dir_igor,\
        "{field}-all/output/entropies.tsv")
    log: os.path.join(log_dir_igor,\
        "merge_recombination_entropies_{field}.dbg")
    conda: env_r_analysis
    threads: config["threads"]["min"]
    params:
        aux = aux_dir_analysis,
    script: os.path.join(script_dir_analysis, "merge_dbs.R")
